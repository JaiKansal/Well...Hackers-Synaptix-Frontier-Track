{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ“ BDH Training for Brain Explorer\n",
                "\n",
                "This notebook trains a Baby Dragon Hatchling (BDH) model on the pathfinding task to achieve **~5% sparsity**.\n",
                "\n",
                "**Expected Time**: 2-4 hours on T4 GPU\n",
                "\n",
                "**Steps**:\n",
                "1. Clone krychu/bdh repository\n",
                "2. Install dependencies\n",
                "3. Train BDH model\n",
                "4. Save checkpoint\n",
                "5. Download `bdh_trained.pth`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Clone Repository"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!git clone https://github.com/krychu/bdh.git\n",
                "%cd bdh"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install torch numpy matplotlib networkx pillow -q"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "from bdh import BDH, BDHParameters\n",
                "from boardpath import BoardPathDataset, BoardPathConfig\n",
                "import time\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Configure Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model configuration matching Brain Explorer\n",
                "params = BDHParameters(\n",
                "    V=5,          # Vocabulary: 0=empty, 1=wall, 2=start, 3=end, 4=path\n",
                "    T=100,        # Sequence length (10x10 board flattened)\n",
                "    H=4,          # Number of heads\n",
                "    N=2048,       # Number of neurons (sparse layer)\n",
                "    D=64,         # Latent dimension\n",
                "    L=12,         # Number of layers\n",
                "    dropout=0.1,\n",
                "    use_rope=True,\n",
                "    use_abs_pos=False\n",
                ")\n",
                "\n",
                "print(f\"Model Configuration:\")\n",
                "print(f\"  Neurons: {params.N}\")\n",
                "print(f\"  Layers: {params.L}\")\n",
                "print(f\"  Heads: {params.H}\")\n",
                "print(f\"  Latent Dim: {params.D}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Create Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset configuration\n",
                "config = BoardPathConfig(\n",
                "    board_size=10,\n",
                "    num_examples=10000,  # 10k training examples\n",
                "    vocab_size=5,\n",
                "    seq_len=100\n",
                ")\n",
                "\n",
                "dataset = BoardPathDataset(config)\n",
                "loader = torch.utils.data.DataLoader(\n",
                "    dataset, \n",
                "    batch_size=32, \n",
                "    shuffle=True,\n",
                "    num_workers=2\n",
                ")\n",
                "\n",
                "print(f\"Dataset: {len(dataset)} examples\")\n",
                "print(f\"Batches per epoch: {len(loader)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Initialize Model & Optimizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = BDH(params)\n",
                "model.to(device)\n",
                "\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "# Count parameters\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f\"Total parameters: {total_params:,}\")\n",
                "print(f\"Trainable parameters: {trainable_params:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_epochs = 50  # Adjust based on convergence\n",
                "losses = []\n",
                "best_loss = float('inf')\n",
                "\n",
                "print(\"ðŸš€ Starting Training...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "for epoch in range(num_epochs):\n",
                "    model.train()\n",
                "    epoch_loss = 0\n",
                "    \n",
                "    for batch_idx, (x, y) in enumerate(loader):\n",
                "        x, y = x.to(device), y.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        # Forward pass\n",
                "        logits, _ = model(x)\n",
                "        \n",
                "        # Compute loss\n",
                "        loss = criterion(logits.view(-1, params.V), y.view(-1))\n",
                "        \n",
                "        # Backward pass\n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
                "        optimizer.step()\n",
                "        \n",
                "        epoch_loss += loss.item()\n",
                "        \n",
                "        # Log progress\n",
                "        if batch_idx % 50 == 0:\n",
                "            print(f\"Epoch {epoch+1}/{num_epochs} | Batch {batch_idx}/{len(loader)} | Loss: {loss.item():.4f}\")\n",
                "    \n",
                "    # Epoch summary\n",
                "    avg_loss = epoch_loss / len(loader)\n",
                "    losses.append(avg_loss)\n",
                "    \n",
                "    elapsed = time.time() - start_time\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Epoch {epoch+1} Complete | Avg Loss: {avg_loss:.4f} | Time: {elapsed/60:.1f}m\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    # Save best model\n",
                "    if avg_loss < best_loss:\n",
                "        best_loss = avg_loss\n",
                "        torch.save(model.state_dict(), 'bdh_best.pth')\n",
                "        print(f\"âœ… New best model saved! Loss: {best_loss:.4f}\\n\")\n",
                "    \n",
                "    # Early stopping if loss is very low\n",
                "    if avg_loss < 0.05:\n",
                "        print(\"ðŸŽ‰ Training converged! Loss < 0.05\")\n",
                "        break\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"âœ… Training Complete!\")\n",
                "print(f\"Total time: {(time.time() - start_time)/60:.1f} minutes\")\n",
                "print(f\"Best loss: {best_loss:.4f}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Save Final Checkpoint"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save final model\n",
                "torch.save(model.state_dict(), 'bdh_trained.pth')\n",
                "print(\"âœ… Final model saved: bdh_trained.pth\")\n",
                "\n",
                "# Also save the best model with a clear name\n",
                "!cp bdh_best.pth bdh_trained.pth\n",
                "print(\"âœ… Best model copied to: bdh_trained.pth\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 9: Verify Sparsity"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test sparsity on a sample\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    # Get a test sample\n",
                "    x_test, _ = dataset[0]\n",
                "    x_test = x_test.unsqueeze(0).to(device)\n",
                "    \n",
                "    # Forward pass with state tracking\n",
                "    logits, output_frames, x_frames, y_frames, attn_frames, logits_frames = model(x_test, capture_frames=True)\n",
                "    \n",
                "    # Compute sparsity\n",
                "    if y_frames:\n",
                "        # Average sparsity across all layers\n",
                "        sparsities = []\n",
                "        for layer_activations in y_frames:\n",
                "            active = (layer_activations > 0).float().mean().item()\n",
                "            sparsities.append(active * 100)\n",
                "        \n",
                "        avg_sparsity = np.mean(sparsities)\n",
                "        print(f\"\\nðŸŽ¯ Sparsity Analysis:\")\n",
                "        print(f\"  Average sparsity: {avg_sparsity:.2f}%\")\n",
                "        print(f\"  Target: ~5%\")\n",
                "        print(f\"  Status: {'âœ… GOOD' if avg_sparsity < 10 else 'âš ï¸ Needs more training'}\")\n",
                "        \n",
                "        print(f\"\\n  Per-layer sparsity:\")\n",
                "        for i, s in enumerate(sparsities):\n",
                "            print(f\"    Layer {i+1}: {s:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 10: Plot Training Loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(losses, linewidth=2)\n",
                "plt.xlabel('Epoch', fontsize=12)\n",
                "plt.ylabel('Loss', fontsize=12)\n",
                "plt.title('BDH Training Loss', fontsize=14, fontweight='bold')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.savefig('training_loss.png', dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print(f\"Final loss: {losses[-1]:.4f}\")\n",
                "print(f\"Best loss: {min(losses):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## âœ… Training Complete!\n",
                "\n",
                "### Next Steps:\n",
                "\n",
                "1. **Download the checkpoint**:\n",
                "   - Look in the **Output** section (right sidebar)\n",
                "   - Find `bdh_trained.pth`\n",
                "   - Click the three dots â†’ Download\n",
                "\n",
                "2. **Deploy to Brain Explorer**:\n",
                "   ```bash\n",
                "   # In your local project\n",
                "   mkdir -p checkpoints\n",
                "   mv ~/Downloads/bdh_trained.pth checkpoints/\n",
                "   \n",
                "   # Restart backend\n",
                "   cd backend/api\n",
                "   python app.py\n",
                "   ```\n",
                "\n",
                "3. **Verify**:\n",
                "   - Backend should show: `ðŸŽ“ TRAINED MODEL MODE`\n",
                "   - Frontend banner should be green: \"Trained Model Active\"\n",
                "   - Sparsity should be ~5% instead of ~25%\n",
                "\n",
                "ðŸŽ‰ **Congratulations! You now have a production-grade trained BDH model!**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}