{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ BDH Pathfinding Training\n",
                "\n",
                "Train BDH to actually solve mazes by predicting the next cell in an optimal path.\n",
                "\n",
                "**Key Innovation**: Set V=100 (number of cells) so BDH directly predicts next cell!\n",
                "\n",
                "**Expected Time**: 30-60 minutes on T4 GPU\n",
                "\n",
                "**IMPORTANT**: \n",
                "- Enable **GPU** (T4 or P100)\n",
                "- Enable **Internet**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Clone Repository & Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Clone BDH repository if not exists\n",
                "if not os.path.exists('bdh'):\n",
                "    !git clone https://github.com/krychu/bdh.git\n",
                "    print(\"‚úÖ Repository cloned\")\n",
                "else:\n",
                "    print(\"‚úÖ Repository already exists\")\n",
                "\n",
                "%cd bdh"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "import torch\n",
                "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
                "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
                "\n",
                "!pip install numpy matplotlib -q\n",
                "print(\"‚úÖ Dependencies installed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Create Pathfinding Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import random\n",
                "from collections import deque\n",
                "from typing import List, Tuple, Optional\n",
                "\n",
                "class PathfindingDataset(torch.utils.data.Dataset):\n",
                "    \"\"\"Dataset for training BDH on pathfinding\"\"\"\n",
                "    \n",
                "    def __init__(self, num_samples=50000, board_size=10, wall_density=0.25, min_path_length=5):\n",
                "        self.num_samples = num_samples\n",
                "        self.board_size = board_size\n",
                "        self.wall_density = wall_density\n",
                "        self.min_path_length = min_path_length\n",
                "        \n",
                "        print(f\"Generating {num_samples} pathfinding samples...\")\n",
                "        self.samples = self._generate_dataset()\n",
                "        print(f\"‚úÖ Generated {len(self.samples)} valid samples\")\n",
                "    \n",
                "    def _bfs_path(self, board, start, end):\n",
                "        \"\"\"Find shortest path using BFS\"\"\"\n",
                "        queue = deque([(start, [start])])\n",
                "        visited = {start}\n",
                "        \n",
                "        while queue:\n",
                "            (row, col), path = queue.popleft()\n",
                "            \n",
                "            if (row, col) == end:\n",
                "                return path\n",
                "            \n",
                "            for dr, dc in [(0, 1), (1, 0), (0, -1), (-1, 0)]:\n",
                "                new_row, new_col = row + dr, col + dc\n",
                "                \n",
                "                if (0 <= new_row < self.board_size and\n",
                "                    0 <= new_col < self.board_size and\n",
                "                    (new_row, new_col) not in visited and\n",
                "                    board[new_row, new_col] != 1):\n",
                "                    \n",
                "                    visited.add((new_row, new_col))\n",
                "                    queue.append(((new_row, new_col), path + [(new_row, new_col)]))\n",
                "        \n",
                "        return None\n",
                "    \n",
                "    def _generate_sample(self):\n",
                "        \"\"\"Generate a single training sample\"\"\"\n",
                "        for _ in range(10):  # Max 10 attempts\n",
                "            # Generate board\n",
                "            board = np.zeros((self.board_size, self.board_size), dtype=np.int64)\n",
                "            for i in range(self.board_size):\n",
                "                for j in range(self.board_size):\n",
                "                    if random.random() < self.wall_density:\n",
                "                        board[i, j] = 1\n",
                "            \n",
                "            # Random start and end\n",
                "            start = (random.randint(0, self.board_size-1), random.randint(0, self.board_size-1))\n",
                "            end = (random.randint(0, self.board_size-1), random.randint(0, self.board_size-1))\n",
                "            \n",
                "            if board[start] == 1 or board[end] == 1 or start == end:\n",
                "                continue\n",
                "            \n",
                "            # Find path\n",
                "            path = self._bfs_path(board, start, end)\n",
                "            \n",
                "            if path and len(path) >= self.min_path_length:\n",
                "                # Create training samples from path\n",
                "                samples = []\n",
                "                for i in range(len(path) - 1):\n",
                "                    board_state = board.copy()\n",
                "                    board_state[start] = 2  # Start\n",
                "                    board_state[end] = 3    # End\n",
                "                    board_state[path[i]] = 4  # Current\n",
                "                    \n",
                "                    next_pos = path[i + 1]\n",
                "                    target_idx = next_pos[0] * self.board_size + next_pos[1]\n",
                "                    \n",
                "                    samples.append((board_state.flatten(), target_idx))\n",
                "                \n",
                "                return samples\n",
                "        \n",
                "        return None\n",
                "    \n",
                "    def _generate_dataset(self):\n",
                "        \"\"\"Generate full dataset\"\"\"\n",
                "        samples = []\n",
                "        attempts = 0\n",
                "        \n",
                "        while len(samples) < self.num_samples and attempts < self.num_samples * 3:\n",
                "            sample_set = self._generate_sample()\n",
                "            if sample_set:\n",
                "                samples.extend(sample_set)\n",
                "            attempts += 1\n",
                "            \n",
                "            if attempts % 1000 == 0:\n",
                "                print(f\"  Generated {len(samples)}/{self.num_samples} samples...\")\n",
                "        \n",
                "        return samples[:self.num_samples]\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.samples)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        board_state, target = self.samples[idx]\n",
                "        return (\n",
                "            torch.from_numpy(board_state).long(),\n",
                "            torch.tensor(target, dtype=torch.long)\n",
                "        )\n",
                "\n",
                "# Create dataset\n",
                "dataset = PathfindingDataset(num_samples=50000, board_size=10)\n",
                "loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)\n",
                "\n",
                "print(f\"\\n‚úÖ Dataset ready: {len(dataset)} samples, {len(loader)} batches\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Create BDH Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from bdh import BDH, BDHParameters\n",
                "\n",
                "# Create BDH with V=100 (number of cells)\n",
                "params = BDHParameters(\n",
                "    V=100,        # 100 cells (10x10 board) - KEY INNOVATION!\n",
                "    T=100,        # Sequence length\n",
                "    H=4,          # Heads\n",
                "    N=2048,       # Neurons\n",
                "    D=64,         # Latent dimension\n",
                "    L=12,         # Layers\n",
                "    dropout=0.1,\n",
                "    use_rope=True,\n",
                "    use_abs_pos=False\n",
                ")\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "model = BDH(params)\n",
                "model.to(device)\n",
                "\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "print(f\"\\n{'='*70}\")\n",
                "print(f\"üß† BDH Model Created\")\n",
                "print(f\"{'='*70}\")\n",
                "print(f\"Parameters: {total_params:,}\")\n",
                "print(f\"Device: {device}\")\n",
                "print(f\"Vocabulary: {params.V} (maps to 10x10 board)\")\n",
                "print(f\"{'='*70}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.nn as nn\n",
                "import time\n",
                "\n",
                "# Training setup\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "num_epochs = 100\n",
                "losses = []\n",
                "accuracies = []\n",
                "best_acc = 0.0\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"üöÄ STARTING TRAINING\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "for epoch in range(num_epochs):\n",
                "    model.train()\n",
                "    epoch_loss = 0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    for batch_idx, (boards, targets) in enumerate(loader):\n",
                "        boards, targets = boards.to(device), targets.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        # Forward pass\n",
                "        logits = model(boards, capture_frames=False)  # [B, T, V=100]\n",
                "        last_logits = logits[:, -1, :]  # [B, 100]\n",
                "        \n",
                "        # Compute loss\n",
                "        loss = criterion(last_logits, targets)\n",
                "        \n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
                "        optimizer.step()\n",
                "        \n",
                "        epoch_loss += loss.item()\n",
                "        \n",
                "        # Accuracy\n",
                "        preds = last_logits.argmax(dim=-1)\n",
                "        correct += (preds == targets).sum().item()\n",
                "        total += targets.size(0)\n",
                "        \n",
                "        if batch_idx % 100 == 0:\n",
                "            elapsed = time.time() - start_time\n",
                "            acc = 100 * correct / total if total > 0 else 0\n",
                "            print(f\"Epoch {epoch+1:3d}/{num_epochs} | \"\n",
                "                  f\"Batch {batch_idx:4d}/{len(loader)} | \"\n",
                "                  f\"Loss: {loss.item():.4f} | \"\n",
                "                  f\"Acc: {acc:.1f}% | \"\n",
                "                  f\"Time: {elapsed/60:.1f}m\")\n",
                "    \n",
                "    # Epoch summary\n",
                "    avg_loss = epoch_loss / len(loader)\n",
                "    accuracy = 100 * correct / total\n",
                "    losses.append(avg_loss)\n",
                "    accuracies.append(accuracy)\n",
                "    \n",
                "    elapsed = time.time() - start_time\n",
                "    print(f\"\\n{'='*70}\")\n",
                "    print(f\"Epoch {epoch+1:3d} Complete | \"\n",
                "          f\"Loss: {avg_loss:.4f} | \"\n",
                "          f\"Acc: {accuracy:.2f}% | \"\n",
                "          f\"Time: {elapsed/60:.1f}m\")\n",
                "    print(f\"{'='*70}\\n\")\n",
                "    \n",
                "    # Save best model\n",
                "    if accuracy > best_acc:\n",
                "        best_acc = accuracy\n",
                "        torch.save(model.state_dict(), 'bdh_pathfinding_trained.pth')\n",
                "        print(f\"‚úÖ New best! Acc: {best_acc:.2f}%\\n\")\n",
                "    \n",
                "    # Early stopping\n",
                "    if accuracy > 95.0:\n",
                "        print(\"üéâ Excellent accuracy! Stopping early.\")\n",
                "        break\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"‚úÖ TRAINING COMPLETE!\")\n",
                "print(f\"Time: {(time.time() - start_time)/60:.1f} minutes\")\n",
                "print(f\"Best accuracy: {best_acc:.2f}%\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Plot Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "ax1.plot(losses, linewidth=2, color='#6366f1')\n",
                "ax1.set_xlabel('Epoch', fontsize=12)\n",
                "ax1.set_ylabel('Loss', fontsize=12)\n",
                "ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "ax2.plot(accuracies, linewidth=2, color='#10b981')\n",
                "ax2.set_xlabel('Epoch', fontsize=12)\n",
                "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
                "ax2.set_title('Training Accuracy', fontsize=14, fontweight='bold')\n",
                "ax2.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('pathfinding_training.png', dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nFinal Results:\")\n",
                "print(f\"  Loss: {losses[-1]:.4f}\")\n",
                "print(f\"  Accuracy: {accuracies[-1]:.2f}%\")\n",
                "print(f\"  Best Accuracy: {best_acc:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Verify Checkpoint"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "if os.path.exists('bdh_pathfinding_trained.pth'):\n",
                "    size_mb = os.path.getsize('bdh_pathfinding_trained.pth') / 1e6\n",
                "    print(f\"‚úÖ Checkpoint saved: bdh_pathfinding_trained.pth ({size_mb:.1f} MB)\")\n",
                "    print(f\"\\nüì• Download this file and place it in your project's checkpoints/ directory\")\n",
                "else:\n",
                "    print(\"‚ùå Checkpoint not found!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚úÖ Training Complete!\n",
                "\n",
                "### Next Steps:\n",
                "\n",
                "1. **Download checkpoint**:\n",
                "   - Find `bdh_pathfinding_trained.pth` in Output section\n",
                "   - Download it\n",
                "\n",
                "2. **Deploy to Brain Explorer**:\n",
                "   ```bash\n",
                "   mv ~/Downloads/bdh_pathfinding_trained.pth checkpoints/\n",
                "   ```\n",
                "\n",
                "3. **Update backend** to use trained model for pathfinding\n",
                "\n",
                "4. **Test** in Pathfinder Live module\n",
                "\n",
                "üéâ **BDH can now actually solve mazes!**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        },
        "kaggle": {
            "accelerator": "gpu",
            "isGpuEnabled": true,
            "isInternetEnabled": true
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}